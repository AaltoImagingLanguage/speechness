<!DOCTYPE html>
	<html lang="en">
	

	<head>
	

	    <meta charset="utf-8">
	    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	    <meta name="description" content="">
	    <meta name="author" content="">
	

	    <title>Conpy</title>
	

	    <!-- Bootstrap core CSS -->
	    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
	

	    <!-- Custom styles for this template -->
	    <link href="../css/simple-sidebar.css" rel="stylesheet">
	

	</head>
	

	<body>
	

	    <div id="wrapper">
	

	        <!-- Sidebar -->
	       <div id="sidebar-wrapper"> 
	            <ul class="sidebar-nav">
	                <li>
	                    <a href="#">Home</a>
	                </li>
	                <li>
	                    <a href="https://github.com/AaltoImagingLanguage/speechness">Github</a>
	                </li>
	                <li>
	                    <a href="reports.html">Supplementary results</a>
	                </li>
	                <li>
	                    <a href="contact.html">Contact information </a>
	                </li>
	                 <li>
	                    <a href="../index.html">Back to project menu</a>
	                </li>
	           </ul>
	        </div> 
	        <!-- /#sidebar-wrapper -->
	

	        <!-- Page Content -->
	        <div id="page-content-wrapper">
	            <div class="container-fluid">
	                <h1> Dynamic time-locking mechanism in the cortical representation of spoken words <br /></h1>
			<p><b>Authors:</b> Nora, A., Faisal, A., Renvall, H., Seol, J., Formisano, E. & Salmelin, R.<br></p>
	                <p><b>Abstract:</b> Human speech has a unique capacity to carry and communicate rich meanings. However, it is not known how the highly dynamic and variable perceptual signal is mapped to existing linguistic and semantic representations. In this novel approach, we utilized the natural acoustic variability of sounds and mapped them to magnetoencephalography (MEG) data using physiologically-inspired machine-learning models. We aimed at determining how well the models, differing in their representation of temporal information, serve to decode and reconstruct spoken words from MEG recordings in 16 healthy volunteers. We discovered that dynamic time-locking of the cortical activation to the unfolding speech input is crucial for the encoding of the acoustic-phonetic features of speech. In contrast, time-locking was not highlighted in cortical processing of non-speech environmental sounds that conveyed the same meanings as the spoken words, including human-made sounds with temporal modulation content similar to speech. The amplitude envelope of the spoken words was particularly well reconstructed based on cortical evoked responses. Our results indicate that speech is encoded cortically with especially high temporal fidelity. This speech tracking by evoked responses may reflect the same mechanism as the frequently reported entrainment of the cortical oscillations to the amplitude envelope of speech. Furthermore, the phoneme content was reflected in cortical evoked responses simultaneously with the spectrotemporal features, pointing to an instantaneous transformation of the unfolding acoustic features into linguistic representations during speech processing.</p>
	

	                <p>The full publication can be found in <a href="https://www.biorxiv.org/content/10.1101/730838v1">BioRxiv</a>.</p>
	

	                <img src="../cover.png" alt="Connectivity">
	            </div>
	        </div>
	        <!-- /#page-content-wrapper -->
	

	    </div>
	    <!-- /#wrapper -->
	

	    <!-- Bootstrap core JavaScript -->
	    <script src="../vendor/jquery/jquery.min.js"></script>
	    <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
	

	    <!-- Menu Toggle Script -->
	    <script>
	    $("#menu-toggle").click(function(e) {
	        e.preventDefault();
	        $("#wrapper").toggleClass("toggled");
	    });
	    </script>
	

	</body>
	

	</html>
